##Scripts for trimming, assembly and annotation of transcriptomes for C. varians (sponge) and G. endoclionum (symbiont)

#Scripts provided here were modified from ones written by M. Matz https://github.com/z0on , E. Meyer https://github.com/Eli-Meyer , C. Kenkel https://github.com/ckenkel/assemblingTranscriptomes, and B. Strehlow https://github.com/bstrehlow

#command below downloads the established scripts from github

git clone  https://github.com/z0on/annotatingTranscriptomes.git

git clone https://github.com/Eli-Meyer/transcriptome_utilities

#Trancriptome pre-processing:
##Determine Original raw reads generated per Species

#copy zipped files to scratch folder

#Unzip fastq files of raw sequences
gunzip Cliona_*.fastq.gz


#to count reads you will see an @ line for each read - it will start with some letter designation, just use that, in this case: @A0
#then the cat - grep - wc pipe line should tell you the number of reads in each of the files of interest.

cat yourfilename.fastq | grep @A0 | wc -l

Ex) cat Cliona_1_S1_L001_R1_001.fastq | grep @A0 | wc -l
Ex) cat Cliona_1_S1_L001_R2_001.fastq | grep @A0 | wc -l

#####Cliona - 10,581,948 (R1); 10,581,948 (R2)


#############Do we need to do this individually for each sample ID????
#Cliona1
#R1: #10,581,948
#R2: #10,581,948

########total: #418,147,642#



##Quality Trimming
# trimming adaptors and quality filtering
# removing reads with greater than 9 sequential "As", and removing Truseq adaptors, discarding reads shorter than 50 nucleotides
# retain only reads with minimum quality score of 20 over at least 80% of the read

#Ex) Cliona1
cat Cliona_1_S1_L001_R1_001.fastq > Cliona1-R1.fastq
cat Cliona_1_S1_L001_R2_001.fastq > Cliona1-R2.fastq


#quality filter using fastx_clipper


###### What does this mean??
######rename target file for naming simplification for each species. Keep both species in separate directories
export L1_R1reads=STR667_Cliona_GTGAAA_L001_R1_001.fastq
export L1_R2reads=STR667_Cliona_GTGAAA_L001_R2_001.fastq



#Cliona
cat R1reads.fastq | fastx_clipper -a AAAAAAAAA -a TTTTTTTTT -a AGATCGGAA -l 50 -Q33 | fastq_quality_filter -Q33 -q 20 -p 80 >r1.trim
cat R2reads.fastq | fastx_clipper -a AAAAAAAAA -a TTTTTTTTT -a AGATCGGAA -l 50 -Q33 | fastq_quality_filter -Q33 -q 20 -p 80 >r2.trim

#Counting reads remaining after quality Trim. Check line header using head r1.trim. Mine was @DQ8. Submit the script below as 'count_reads.job'
grep @D8Q r1.trim | wc -l
grep @D8Q r2.trim | wc -l


############## CUTADAPT
cutadapt -b "G{100}" -o Cliona4-R1-trim1.fastq.gz Cliona4-R1.fastq.gz --cores=8
cutadapt -b "G{100}" -o Cliona4-R2-trim1.fastq.gz Cliona4-R2.fastq.gz --cores=8
cutadapt -b AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -o Cliona4-R1-trim2.fastq.gz Cliona4-R1-trim1.fastq.gz --cores=8
cutadapt -b AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -o Cliona4-R2-trim2.fastq.gz Cliona4-R2-trim1.fastq.gz --cores=8
cutadapt -b AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -o Cliona4-R1-trim3.fastq.gz Cliona4-R1-trim2.fastq.gz --cores=8
cutadapt -b AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -o Cliona4-R2-trim3.fastq.gz Cliona4-R2-trim2.fastq.gz --cores=8






#make sure that the count has decreased as this is the goal of the trim.

#Trimmed counts for Cliona:

#####Cliona R1, L1 - 85342467
#####Cliona R2, L1 - 79197805 (total = 164,540,270)
#####Cliona R1, L2 - 85857646
#####Cliona R2, L2 - 79496554 (total = 165,354,200)



#####cat r1.trim r1_l2.trim > r1.trim.cat.   #### Shouldn't matter for us since our data comes from 1 Lane
#####cat r2.trim r2_l2.trim > r2.trim.cat

#####count concatinated reads. Submit as job with PBS wrapper. Counts will appear in the generated output file.

#####grep @D8Q r1.trim.cat | wc -l
#####grep @D8Q r2.trim.cat | wc -l

######R1 and R2 counts for Cliona:

######Cliona R1.cat - 171200113
######Cliona R2.cat - 158694359

########## Re-pairing sequences:
# At this point you may have to make more space in your working directory as each step nearly doubles the data.

perl /annotatingTranscriptomes/rePair.pl r1.trim.cat r2.trim.cat



#How many reads are paired and unpaired after quality trimming? qsub the following count jobscript with a PBS wrapper.

grep @D8Q R1_r1.trim.cat | wc -l
grep @D8Q R2_r2.trim.cat | wc -l
grep @D8Q Unp_r1.trim.cat_r2.trim.cat | wc -l


#R1 and R2 paired counts should be the same. If they are not, then the scratch folder likely ran out of memory.

#Repaired counts for Cliona:
#R1_Cliona 133644264
#R2_Cliona 133644264
#UnPair_Cliona 62605944

#####Deduplicating transcriptome
#Removes duplicated reads prior to transcriptome assembly (PCR duplicates).
#Input must be fastq files, trimmed, quality-filtered and sorted into left, right and unpaired reads.
#Identifies duplicates based on identity of bases 5-30 on both left and right ends (if paired reads are supplied)or in unpaired reads.

perl /annotatingTranscriptomes/dedupTranscriptome.pl left=R1_r1.trim.cat right=R2_r2.trim.cat unp=Unp_r1.trim.cat_r2.trim.cat

#How many dedup reads left? Read number should decrease again
#NOTE: these are the values reported in the manuscript
#The values below are reported in the output file after the script is done. No need to run a counting script.

#Cliona
#PAIRED: kept 50,524,403 out of 133,644,264
#UNPAIRED: kept 8,705,889 out of 62,605,944


##### putting reads together with suffixes /1 (for left and unpaired ones) and /2 for right reads: labs.job

cat R1_r1.trim.cat.dedup | perl -pe 's/^(\@D8Q.+)$/$1\/1/' > R1p_suf1.fastq && cat Unp_r1.trim.cat_r2.trim.cat.dedup | perl -pe 's/^(\@D8Q.+)$/$1\/1/' >> R1p_suf1.fastq
cat R2_r2.trim.cat.dedup | perl -pe 's/^(\@D8Q.+)$/$1\/2/' > R2p_suf2.fastq

###########
#Transcriptome assembly using Trinity

#can increase CPU number with computing availability

Trinity --seqType fq --max_memory 25G --left R1p_suf1.fastq --right R2p_suf2.fastq --CPU 6

######assembly stats

seq_stats.pl Trinity.fasta

#cliona
#Trinity.fasta
#-------------------------
#397585 sequences.
#849 average length.
#22485 maximum length.
#182 minimum length.
#N50 = 1425
#337.7 Mb altogether (337682700 bp).
#0 ambiguous Mb. (0 bp, 0%)
#0 Mb of Ns. (0 bp, 0%)
#-------------------------




#########################################################


##### 1. Remove contigs <400bp #####

#FIRST cleaning step - according to Kitchen et al. G3 November 1, 2015 vol. 5 no. 11 2441-2452 doi: 10.1534/g3.115.020164
#Assemblies included many small contigs (on average, 47% were <400 bp) that were unlikely to provide significant matches, so for analyses based on sequence homology we considered only contigs â‰¥400 bp (average n = 91,792).
#use removesmalls.pl to get rid of contigs < specified length
#https://github.com/drtamermansour/p_asteroides/blob/master/scripts/removesmalls.pl


perl /transcriptome_utilities/removesmalls.pl 400 Trinity.fasta > Cli_Trinity-l400.fasta

#cliona final
#cliona_Trinity-l400.fasta
#-------------------------
#225126 sequences.
#1284 average length.
#22485 maximum length.
#400 minimum length.
#N50 = 1696
#289.1 Mb altogether (289074034 bp).
#0 ambiguous Mb. (0 bp, 0%)
#0 Mb of Ns. (0 bp, 0%)
#-------------------------



#### 2. Remove rRNA and mitoRNA ####

#following Kitchen et al, remove reads matching to rRNA and mitoRNA (contamination)

#Remove contaminant sponge sequences from transcriptome; note: must use modified script that updates blastall to blast+ usage
########## making the script RemoveContamSeq.pl may take some modificaitons based on your computer. Some are below, but the final version I used is here

#for the original manuscript, we made the following replacements
#changed line 1 to:
#!/usr/local/bioperl/1.6.924/bin/perl
#add path to target in line 74, e.g.:
#system("/export/scratch/bstrehlo/Sample_STR667_Cliona/scripts/transcriptome_utilities/ExcludeFasta1.pl discard.list $rfil >tq.fasta");
#and 116
#system("/export/scratch/bstrehlo/Sample_STR667_Cliona/scripts/transcriptome_utilities/invert_seq_ext1.pl discard.list $rfil >tq.fasta");

#save modified file as RemoveContamSeq6.pl

# also updated invert_seq_ext1.pl, line 1:
#!/usr/local/bioperl/1.6.924/bin/perl
 /export/scratch/bstrehlo/Sample_STR667_Cliona/scripts/transcriptome_utilities/RemoveContamSeq6.pl

#also possible:
#Notes on modifiers for RemoveContamSeq.pl for AIMS HPC - comment out blastall checks #$dep1 ="blastall" ; #next line
#then where script calls for blastall, replace with legacy_blast before 'blastall' and proper path after -o (/opt/apps/blast/2.2.28/bin):
#change all blastall to legacy_blast

##########

#Download reference data
#Ribosomal rna
#arb-silva.de_2019-07-16_id680707.tgz not: this is a newer version than the one above, but it was the top hit and seemed to be the best choice
#See https://www.arb-silva.de/ for ribosomal dna
#downloaded fasta sequence (without gaps)

#mitochondrial rna https://www.ncbi.nlm.nih.gov/nuccore/DQ915601

perl RemoveContamSeq6.pl type=blastn score=45 reads=Cli_Trinity-l400.fasta contam=rRNA,aqu_mitochondria_rna.fasta contam=Mito,arb-silva.de_2019-07-16_id680707.fasta table=CliContamsSearch_rRNA_mito.txt passed=Cli_Trinity-l400_NOrRNAmito.fasta

#carterio  roughly the same
#136510 sequences in input file
#70 sequences look like contaminants
#	Mito	61
#	rRNA	9
#136494 sequences passed all tests

#Removed sequences are found in 'discard.list'

#cliona

#For Cliona Cli_Trinity-l400.fasta
#215806 sequences in input file
#18 sequences look like contaminants
#	Mito	27
#	rRNA	18
#215761 sequences passed all tests

############## holobiont GC content (BBMap package):

stats.sh input=transcriptome.fasta

#########################################################
#Simultaneously Identify the most likely origin of each sequence
#by comparison with a protein DB from a single close relative, and one or more
#databases of likely contaminants. e.g. for sponges, A. queenslandica would be a
#good target and Symbiodinium would be a likely contaminant for Cliona.
#Each sequence is assigned to the source which it matches best.
#*Note: same principle as Kitchen et al paper, save blasted to Sym Kawagutii predicted proteome (more complete than minutum)
#http://web.malab.cn/symka_new/download.jsp

#NOTE before running blasts, must shorten fasta headers to avoid error messages in blast output - try this fix:

sed -e 's/>* .*$//' original.fasta > truncated.fasta

sed -e 's/>* .*$//' Cli_Trinity-l400_NOrRNAmito.fasta > Cli_Trinity-l400_NOrRNAmito-truncated.fasta

#carterio

sed -e 's/>* .*$//' Cart_Trinity-l400_NOrRNAmito.fasta > Cart_Trinity-l400_NOrRNAmito-truncated.fasta

#Also get and truncate reference sequences from a. queenslandica. You can comment back in each line for each peace of data.

#2019 - it seems the degnan website is down, so I got the proteome of queenslandica from Uniprot
#https://www.uniprot.org/proteomes/UP00000787
#aqu_proteins.fasta

#Reference for Symbiodiniaceae
#http://web.malab.cn/symka_new/download.jsp
#Symbiodinium_kawagutii.0819.final.gene.pep

##carterio
UP000007879_400682.fasta = aqu_proteins.fasta

cat aqu_proteins.fasta | grep '>' | sed -e 's/>* .*$//' | sort -u | wc -l
#43435 -matches number in Uniprot

cat aqu_proteins.fasta| grep '>' | wc -l
#43435 -matches number in Uniprot

cat Symbiodinium_kawagutii.0819.final.gene.pep | grep '>' | sed -e 's/>* .*$//' | sort -u | wc -l
#36850

cat Symbiodinium_kawagutii.0819.final.gene.pep| grep '>' | wc -l
#36850

##truncate databases:

sed -e 's/>* .*$//' Symbiodinium_kawagutii.0819.final.gene.pep> Symbiodinium_kawagutii.0819.final.gene-truncated.pep

sed -e 's/>* .*$//' aqu_proteins.fasta > aqu_proteins-truncated.fasta

#######fixing TaxaOrigin and CompareContam.pl script
#again, this script needed some changes to run on the AIMS HPC, as follows
#-commented out system check for blastall; replaced inline blastall calls with legacy_blast.pl and added path to bioperl locally
#-within calls to blastall OR blastx, replaced -a 4 with -a 16 (to use 16 cores instead of 4); or -cpu to 16
#-commented out all calls for system("date") as this was returning syntax error - not sure why, but date calls don't seem necessary
#saved as 'CompareContamSeg3.pl'

makeblastdb -in aqu_proteins-truncated.fasta -dbtype prot

makeblastdb -in Symbiodinium_kawagutii.0819.final.gene-truncated.pep -dbtype prot

#carterio
perl /transcriptome_utilities/CompareContamSeq3.pl Cart_Trinity-l400_NOrRNAmito-truncated.fasta 45 aqu_proteins-truncated.fasta Symbiodinium_kawagutii.0819.final.gene-truncated.pep

#cliona
perl /transcriptome_utilities/CompareContamSeq3.pl Cliona_unstranded_Trinity-l400_NOrRNAmito-truncated.fasta 45 aqu_proteins-truncated.fasta Symbiodinium_kawagutii.0819.final.gene-truncated.pep

#for cliona final
#225089 sequences input.
#83752 of these matched aqu_proteins-truncated.fasta more closely than any contaminants.
#35648 matched contaminants more closely than aqu_proteins-truncated.fasta.
#105689 matched none of the supplied DB (nomatch.screened.fasta).

#carterio final
#136494 sequences input.
#67710 of these matched aqu_proteins-truncated.fasta more closely than any contaminants.
#1520 matched contaminants more closely than aqu_proteins-truncated.fasta.
#67264 matched none of the supplied DB (nomatch.screened.fasta).

###############Determine most likely source for each adig sequence in TS assembly based on taxonomic ID of each sequence's best match in
###############NCBI's nr database

#NOTE: nr database and taxdump files downloaded 25 August 2016 - into /NCBI in WORK directory
#blast files are already located on AIMS HPC under /export/databases/NCBI/nr

#carterio
update_blastdb --passive nr

ls *.gz | time parallel -j+0 tar -zxvf

wget ftp://ftp.ncbi.nih.gov/pub/taxonomy/taxdump.tar.gz
tar -zxvf taxdump.tar.gz

mkdir DBdir

#Get taxa identifiers
#carterio

perl /transcriptome_utilities/taxfiles.pl

#sent database files to DBdir directory
scp ls strehlow@fe.deic.sdu.dk:/work/sducanfield2/DBdir

# splitting the transcriptome into 20 chunks to parallelize and/or decrease computing time per chunk

#Carterio - tried with 20 chunks first to do a test
splitFasta.pl Cart_target.screened.fasta 20

####cliona final
splitFasta.pl Cliona_final_target.screened.fasta 30

#create list of commands for blasting
ls subset1_Cart_target.screened.fasta | perl -pe 's{^(\S+)$}{blastx -query $1 -db /mnt/nanopore/Transcriptomics/Unaligned_150904_SN7001375_0225_BH7NG2BCXX/Project_STR667/Sample_STR667_Carterio/NCBI_nr/nr -evalue 0\.00001 -num_threads 8 -num_descriptions 5 -num_alignments 5 -out $1.br}' > bl_cart_test

#produced file 'bl_cart_test' containing individual commands. Ran them separately
blastx -query subset1_Cart_target.screened.fasta -db /mnt/nanopore/Transcriptomics/Unaligned_150904_SN7001375_0225_BH7NG2BCXX/Project_STR667/Sample_STR667_Carterio/NCBI_nr/nr -evalue 0.00001 -num_threads 8 -num_descriptions 5 -num_alignments 5 -out subset1_Cart_target.screened.fasta.br

perl /export/home/a-e/bstrehlo/bin/TaxaOriginByBlast2.pl aqu_proteins-truncated.screened.fasta /export/databases/NCBI/nr /export/scratch/bstrehlo/Sample_STR667_Cliona/bin 0.00001 kingdom false no  Cli_aqu2.chunk.100.blast

#generate combined blast report from files with prefix Cli and suffix .blast

cat Cli*.blast > Allblast.br

grep -B 5 "No hits found" Allblast.br | grep "Query=" | sed 's/Query= //g' > NoNRmatchListAqu.tab

#Matches to metazoan taxa

#segment.job
grep "Metazoa" AllcontigParseAqu.tab | cut -f 1 > Metazoa.tab
grep "Chordata" AllcontigParseAqu.tab | cut -f 1 > Chordata.tab
grep "Arthropoda" AllcontigParseAqu.tab | cut -f 1 > Arthropoda.tab
grep "Actinopteri" AllcontigParseAqu.tab | cut -f 1 > Actinopteri.tab

###for Symbiodiniaceae

grep "Dinoflagellata" AllcontigParseSym.tab | cut -f 1 > Dinoflagellata.tab
grep "Dinophyceae" AllcontigParseSym.tab | cut -f 1 > Dinophyceae.tab
grep "Suessiales" AllcontigParseSym.tab | cut -f 1 > Suessiales.tab
grep "Symbiodiniaceae" AllcontigParseSym.tab | cut -f 1 > Symbiodiniaceae.tab
grep "Chromerida" AllcontigParseSym.tab | cut -f 1 > Chromerida.tab

#nomatch within nr
grep -B 5 "No hits found" myblast.br | grep "Query=" | sed 's/Query= //g' > NonrmatchListsymbiodinium.tab

cat Dinoflagellata.tab Dinophyceae.tab Suessiales.tab Symbiodiniaceae.tab Chromerida.tab NonrmatchListsymbiodinium.tab > Symbiodinium_AllGoodContigs.tab

#verify everything that should have been blasted

#Combining 'good' contigs for final transcriptomes
cat Metazoa.tab Chordata.tab Arthropoda.tab Actinopteri.tab NoNRmatchListAqu.tab > Cliona_Parsed_AllGoodContigs.tab

#check numbers
cat Cliona_Parsed_AllGoodContigs.tab | wc -l

cat Carterio_Parsed_AllGoodContigs.tab | wc -l

#Symbiodinium
cat Symbiodinium_AllGoodContigs.tab | wc -l

#########Ultimately, to sort fasta based on NR blast taxonomic assignments, need list of contig names to be included
#use samtools, e.g:
cat Symbiodinium_AllGoodContigs.tab | xargs -n 1 samtools faidx Symbiodinium.fasta > symbio.fasta

#Get stats:

perl seq_stats.pl cliona.fasta

#symbio final
#symbio.fasta
##-------------------------
#28670 sequences.
#1375 average length.
#21103 maximum length.
#400 minimum length.
#N50 = 1672
#39.4 Mb altogether (39418006 bp).
#0 ambiguous Mb. (0 bp, 0%)
#0 Mb of Ns. (0 bp, 0%)
#-------------------------


#cliona final
#cliona.fasta
#-------------------------
#82895 sequences.
#1756 average length.
#22485 maximum length.
#400 minimum length.
#N50 = 2369
#145.6 Mb altogether (145604954 bp).
#0 ambiguous Mb. (0 bp, 0%)
#0 Mb of Ns. (0 bp, 0%)
#-------------------------


#carterio final
#carterio.fasta
#-------------------------
#67304 sequences.
#3024 average length.
#26809 maximum length.
#400 minimum length.
#N50 = 4355
#203.5 Mb altogether (203507585 bp).
#0 ambiguous Mb. (0 bp, 0%)
#0 Mb of Ns. (0 bp, 0%)
#-------------------------
